{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e640e2e3-3aeb-467e-a214-b0f413ce4af8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Este projeto implementa um assistente de IA generativa utilizando Python e LLMs, com foco em construção de pipelines inteligentes e integração com dados externos. São aplicados conceitos de engenharia de prompts, uso de PromptTemplate/ChatPromptTemplate, geração de saídas estruturadas (JSON/stream) e técnicas de Retrieval-Augmented Generation (RAG) para consulta de documentos (.txt e .pdf).\n",
    "\n",
    "Como caso de uso, foi desenvolvido um assistente para planejamento de viagens capaz de sugerir locais, analisar informações contextuais e responder de forma orientada a dados. A solução prioriza modularidade, escalabilidade e boas práticas no desenvolvimento de aplicações baseadas em IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9c76162-5b97-40fd-9769-7fc0d64f5f03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " LangChain = É um framework que ajuda a construir aplicações com IA generativa\n",
    " \n",
    " LLM = Modelo de linguagem usado é da OpenAI (Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c9fa5077-98c6-461d-bd2e-476065661096",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install required packages"
    }
   },
   "outputs": [],
   "source": [
    "### requirements.txt\n",
    "%pip install \\\n",
    "  openai==1.86.0 \\\n",
    "  langchain==0.3.25 \\\n",
    "  langchain-openai==0.3.22 \\\n",
    "  langgraph==0.4.8 \\\n",
    "  python-dotenv==1.1.0 \\\n",
    "  faiss-cpu==1.11.0 \\\n",
    "  langchain-community==0.3.25 \\\n",
    "  pypdf==5.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea6673ef-7935-42c5-b112-3470e7388eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"ccc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f251b3-7420-44d2-828f-3da20350462d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os \n",
    "\n",
    "api_key=OPENAI_API_KEY\n",
    "\n",
    "numero_dias= 7\n",
    "numero_criancas= 2\n",
    "atividade= \"natureza\"\n",
    "\n",
    "modelo_de_prompt = PromptTemplate(\n",
    "   template = \"\"\"\n",
    "   Criar um roteiro de viagem de {numero_dias} dias,\n",
    "    para uma familiar com {numero_criancas} criancas,\n",
    "    que gostam de {atividade}\n",
    "   \"\"\"\n",
    ")\n",
    "\n",
    "prompt = modelo_de_prompt.format(\n",
    "    numero_dias=numero_dias,\n",
    "    numero_criancas=numero_criancas,\n",
    "    atividade=atividade\n",
    ")\n",
    "print( \"Prompt: \\n\", prompt)\n",
    "\n",
    "modelo = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.5,  #### nível de criatividade do modelo: quanto mais próximo de 2, mais criativo; quanto mais próximo de 0, menos criativo\n",
    "    api_key=api_key\n",
    ")\n",
    "resposta = modelo.invoke(prompt)\n",
    "print(resposta.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a793b6-2173-4b1e-9788-b5ae3ca53b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Orquestramento com cadeias LCEL no Lanchain = pipeline de execução de LLM\n",
    "## 1- Modelo do prompt\n",
    "## 2- Estrutura do LMM \n",
    "## 3- Saida de resposta \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os \n",
    "\n",
    "api_key=OPENAI_API_KEY\n",
    "\n",
    "modelo_cidade = PromptTemplate(\n",
    "   template = \"\"\"\n",
    "   Sugira uma cidade dado meu interesse por {interesse}.\n",
    "   \"\"\",\n",
    "   input_variavels=[\"interesse\"])\n",
    "\n",
    "modelo = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.5,  #### nível de criatividade do modelo: quanto mais próximo de 2, mais criativo; quanto mais próximo de 0, menos criativo\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "cadeia= modelo_cidade | modelo | StrOutputParser()\n",
    "\n",
    "resposta = cadeia.invoke({\"interesse\": \"praias\"})\n",
    "print(resposta)\n",
    "\n",
    "\n",
    "##Esse código monta uma cadeia LCEL no LangChain que recebe um interesse do usuário, formata dinamicamente um prompt, envia para um modelo da OpenAI e retorna a resposta em texto limpo. É uma forma declarativa de orquestrar chamadas de LLM."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "py.IA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
