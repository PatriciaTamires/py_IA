{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e640e2e3-3aeb-467e-a214-b0f413ce4af8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Este projeto implementa um assistente de IA generativa utilizando Python e LLMs, com foco em construção de pipelines inteligentes e integração com dados externos. São aplicados conceitos de engenharia de prompts, uso de PromptTemplate/ChatPromptTemplate, geração de saídas estruturadas (JSON/stream) e técnicas de Retrieval-Augmented Generation (RAG) para consulta de documentos (.txt e .pdf).\n",
    "\n",
    "Como caso de uso, foi desenvolvido um assistente para planejamento de viagens capaz de sugerir locais, analisar informações contextuais e responder de forma orientada a dados. A solução prioriza modularidade, escalabilidade e boas práticas no desenvolvimento de aplicações baseadas em IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9c76162-5b97-40fd-9769-7fc0d64f5f03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " ### LangChain = É um framework que ajuda a construir aplicações com IA generativa\n",
    " ### LLLM = Modelo de linguagem usado é da OpenAI (Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c9fa5077-98c6-461d-bd2e-476065661096",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install required packages"
    }
   },
   "outputs": [],
   "source": [
    "### requirements.txt\n",
    "%pip install \\\n",
    "  openai==1.86.0 \\\n",
    "  langchain==0.3.25 \\\n",
    "  langchain-openai==0.3.22 \\\n",
    "  langgraph==0.4.8 \\\n",
    "  python-dotenv==1.1.0 \\\n",
    "  faiss-cpu==1.11.0 \\\n",
    "  langchain-community==0.3.25 \\\n",
    "  pypdf==5.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ebcd3a9-20c1-4c91-b153-45e1acb2276a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "###Bibliotecas\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from pydantic import Field, BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from langchain.globals import set_debug\n",
    "import os\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "py.IA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
